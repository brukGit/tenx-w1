{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "# Define the path to the src directory\n",
    "src_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "sys.path.insert(0, src_dir)\n",
    "\n",
    "# Delete the eda and data_loader modules if they exist\n",
    "if 'text_analysis' in sys.modules:\n",
    "    del sys.modules['text_analysis']\n",
    "if 'data_loader' in sys.modules:\n",
    "    del sys.modules['data_loader']\n",
    "\n",
    "from text_analysis import TextAnalysis\n",
    "from data_loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean data\n",
    "data_loader = DataLoader(\"../data/raw_analyst_ratings/raw_analyst_ratings.csv\")\n",
    "df = data_loader.load_data()\n",
    "df = data_loader.clean_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline sentiments:\n",
      "                                                  headline  polarity  \\\n",
      "0                  Stocks That Hit 52-Week Highs On Friday      0.00   \n",
      "1               Stocks That Hit 52-Week Highs On Wednesday      0.00   \n",
      "2                            71 Biggest Movers From Friday      0.00   \n",
      "3             46 Stocks Moving In Friday's Mid-Day Session      0.00   \n",
      "4        B of A Securities Maintains Neutral on Agilent...      0.00   \n",
      "...                                                    ...       ...   \n",
      "1407323             Top Narrow Based Indexes For August 29      0.15   \n",
      "1407324  Recap: Wednesday's Top Percentage Gainers and ...      0.15   \n",
      "1407325  UPDATE: Oppenheimer Color on China Zenix Auto ...      0.00   \n",
      "1407326  Oppenheimer Initiates China Zenix At Outperfor...      0.00   \n",
      "1407327  China Zenix Auto International Opens For Tradi...      0.00   \n",
      "\n",
      "         subjectivity  \n",
      "0                0.00  \n",
      "1                0.00  \n",
      "2                0.00  \n",
      "3                0.00  \n",
      "4                0.00  \n",
      "...               ...  \n",
      "1407323          0.45  \n",
      "1407324          0.35  \n",
      "1407325          0.00  \n",
      "1407326          0.00  \n",
      "1407327          0.00  \n",
      "\n",
      "[1407328 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Perform sentiment analysis\n",
    "ta = TextAnalysis(df)\n",
    "# Obtain textual lengths statistics\n",
    "sentiment = ta.perform_sentiment_analysis()\n",
    "print(\"Headline sentiments:\")\n",
    "print(sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headline keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Headline keywords count:\n",
      "vs          162099\n",
      "stocks      161776\n",
      "est         140604\n",
      "eps         128897\n",
      "market      120558\n",
      "             ...  \n",
      "tuesday      21045\n",
      "industry     20981\n",
      "etf          20908\n",
      "dividend     20842\n",
      "30           20809\n",
      "Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of articles per publisher\n",
    "keyword_counts = ta.extract_keywords()\n",
    "print(\"\\nHeadline keywords count:\")\n",
    "print(keyword_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\bab\\AppData\\Local\\Temp\\ipykernel_13140\\1925043443.py\", line 2, in <module>\n",
      "    topics =ta.topic_modeling()\n",
      "  File \"e:\\Studies\\tenx\\w1\\src\\text_analysis.py\", line 65, in topic_modeling\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1372, in fit_transform\n",
      "    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1259, in _count_vocab\n",
      "    for feature in analyze(doc):\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 113, in _analyze\n",
      "    doc = ngrams(doc, stop_words)\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 242, in _word_ngrams\n",
      "    def _word_ngrams(self, tokens, stop_words=None):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"e:\\Studies\\tenx\\w1\\venv\\lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Topic modeling for headlines\n",
    "topics =ta.topic_modeling()\n",
    "print(\"\\nTopics:\")\n",
    "print(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
